{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用训练好的模型进行测试\n",
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess,path)\n",
    "# print(sess.run(loss,feed_dict={x: batch_img,y: batch_labels,keep_prob:1.0}))\n",
    "# 关键就是这几句，因为第一句需要保存变量，所以需要在代码内添加与训练时定义相同的变量\n",
    "# 因为我实在不知道该怎么简化需要的代码，就把训练时定义的全部拷过来了\n",
    "# 然后path就是存放训练好的模型的路径\n",
    "# print哪里与训练时喂的东西要一致\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 是用matlab来产生的h5文件，data字段存的是眼图数据 labels字段存的是误码率\n",
    "def read_h5(path):\n",
    "    f = h5py.File(path)\n",
    "    img = np.transpose(f['data'])\n",
    "    img = np.float32(img)\n",
    "    labels = np.float32(f['labels'])\n",
    "    return img,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 跟着网上学的next_batch喂给placeholder\n",
    "def next_batch(data, labels, batch_size):  \n",
    "    index = [ i for i in range(0,len(labels)) ]  \n",
    "    #np.random.shuffle(index)  # 打乱顺序\n",
    "    batch_data = []\n",
    "    batch_labels = [] \n",
    "    for i in range(0,batch_size):  \n",
    "        data_app = np.reshape(data[index[i],:,:],[-1,360*460])# 这里使用np.reshape,而不使用tf.reshape因为使用了后者报错了，似乎是格式不对\n",
    "        # 就是这个错  setting an array element with a sequence.\n",
    "        batch_data.append(data_app[0])# 有[0]是因为data_app的结果是[1，165600],这样喂给placeholder时就是[batch_size,1,165600]\n",
    "        # 而不是想要的[batch_size,165600]\n",
    "        batch_labels.append(-np.log2(labels[index[i]]+1e-5))# 因为误码率是在0-0.3左右，区分度不高，所以就采用-log2(ber+1e-5)\n",
    "        # 负号是为了让标签为正值,以2为底是感觉好随便取的，添加1e-5是为了避免误码率为0时的情况\n",
    "    return batch_data, batch_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "test_path = 'F:/code/eyediagram/shibai/eyediagram_sur.h5'\n",
    "sur_img,sur_labels = read_h5(test_path)\n",
    "\n",
    "def Variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.mean(var)\n",
    "        tf.summary.scalar('mean',mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.squre(var-mean)))#标准差公式\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "\n",
    "#初始化权值        \n",
    "def weight_variable(shape,name):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)#生成一个截断的正态分布\n",
    "    return tf.Variable(initial,name)\n",
    "\n",
    "# 初始化偏置值\n",
    "def bias_variable(shape,name):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial,name)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    #x input tensor of shape `[batch批次大小, in_height长, in_width宽, in_channels通道数（黑白为1，彩色为3]`\n",
    "    #W filter / kernel 滤波器卷积核tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "    #`strides[0] = strides[3] = 1`. strides[1]代表x方向的步长，strides[2]代表y方向的步长\n",
    "    #padding: A `string` from: `\"SAME在外补0\", \"VALID不补0\"`\n",
    "    #2d表示二维卷积操作\n",
    "    return tf.nn.conv2d(x,W,[1,1,1,1],padding='SAME')\n",
    "\n",
    "def max_pooling_2x2(x):\n",
    "    #ksize [1,x,y,1]窗口大小\n",
    "    #ksize[0,3]默认为1，[1，2]为窗口大小\n",
    "    # strides 步长\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32,[None,165600],name='x_input')# 360*460\n",
    "    y = tf.placeholder(tf.float32,[None,1],name = 'y_input')#ber\n",
    "    with tf.name_scope('x_image'):\n",
    "        #向量转换成图片形状\n",
    "        #改变x的格式转为4D的向量[batch, in_height, in_width, in_channels]`\n",
    "        #-1就是batch_size的大小\n",
    "        x_image = tf.reshape(x,[-1,360,460,1],name='x_image')\n",
    "        \n",
    "#第一个卷积层        \n",
    "with tf.name_scope('conv1'):\n",
    "    with tf.name_scope('conv1_w'):\n",
    "        #5*5的采样窗口，1/32表示输入/输出通道数\n",
    "        conv1_w = weight_variable([5,5,1,32],name='conv1_w') # 32个卷积核\n",
    "    with tf.name_scope('conv1_b'):\n",
    "        #一个卷积核一个偏置\n",
    "        conv1_b = bias_variable([32],name='conv1_b')\n",
    "    #把x_image和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数    \n",
    "    with tf.name_scope('conv2d_1'):\n",
    "        conv2d_1 = conv2d(x_image,conv1_w) + conv1_b\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv_1 = tf.nn.relu(conv2d_1)\n",
    "    with tf.name_scope('conv1_pool'):\n",
    "        conv1_pool = max_pooling_2x2(h_conv_1)\n",
    "        \n",
    "#第二个卷积层        \n",
    "with tf.name_scope('conv2'):\n",
    "    with tf.name_scope('conv2_w'):\n",
    "        conv2_w = weight_variable([5,5,32,64],name='conv2_w')\n",
    "    with tf.name_scope('conv2_b'):\n",
    "        conv2_b = bias_variable([64],name='conv2_b')\n",
    "    with tf.name_scope('conv2d_2'):\n",
    "        conv2d_2 = conv2d(conv1_pool,conv2_w) + conv2_b\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv_2 = tf.nn.relu(conv2d_2)\n",
    "    with tf.name_scope('conv2_pool'):\n",
    "        conv2_pool = max_pooling_2x2(h_conv_2)\n",
    "        \n",
    "#第三个卷积层        \n",
    "with tf.name_scope('conv3'):\n",
    "    with tf.name_scope('conv3_w'):\n",
    "        conv3_w = weight_variable([5,5,64,128],name='conv3_w')\n",
    "    with tf.name_scope('conv3_b'):\n",
    "        conv3_b = bias_variable([128],name='conv3_b')\n",
    "    with tf.name_scope('conv2d_3'):\n",
    "        conv2d_3 = conv2d(conv2_pool,conv3_w) + conv3_b\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv_3 = tf.nn.relu(conv2d_3)\n",
    "    with tf.name_scope('conv3_pool'):\n",
    "        conv3_pool = max_pooling_2x2(h_conv_3)\n",
    "        \n",
    "#第四个卷积层        \n",
    "with tf.name_scope('conv4'):\n",
    "    with tf.name_scope('conv4_w'):\n",
    "        conv4_w = weight_variable([5,5,128,80],name='conv4_w')\n",
    "    with tf.name_scope('conv4_b'):\n",
    "        conv4_b = bias_variable([80],name='conv4_b')\n",
    "    with tf.name_scope('conv2d_4'):\n",
    "        conv2d_4 = conv2d(conv3_pool,conv4_w) + conv4_b\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv_4 = tf.nn.relu(conv2d_4)\n",
    "    with tf.name_scope('conv4_pool'):\n",
    "        conv4_pool = max_pooling_2x2(h_conv_4)\n",
    "        \n",
    "#第五个卷积层        \n",
    "with tf.name_scope('conv5'):\n",
    "    with tf.name_scope('conv5_w'):\n",
    "        conv5_w = weight_variable([5,5,80,20],name='conv5_w')\n",
    "    with tf.name_scope('conv5_b'):\n",
    "        conv5_b = bias_variable([20],name='conv5_b')\n",
    "    with tf.name_scope('conv2d_5'):\n",
    "        conv2d_5 = conv2d(conv4_pool,conv5_w) + conv5_b\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv_5 = tf.nn.relu(conv2d_5)\n",
    "    with tf.name_scope('conv5_pool'):\n",
    "        conv5_pool = max_pooling_2x2(h_conv_5)\n",
    "\n",
    "#360*460的图片第一次卷积后还是360*460，第一次池化后变为180*230\n",
    "#第二次卷积后为180*230，第二次池化后变为了90*115\n",
    "# 也不知道算对没有，但是都通过运行了，应该没问题，我是到奇数时添加1再除2\n",
    "#进过上面操作后得到20张12*15的平面\n",
    "\n",
    "#第一个全连接层        \n",
    "with tf.name_scope('fc1'):\n",
    "    with tf.name_scope('fc1_w'):\n",
    "        fc1_w = weight_variable([12*15*20,512],name='fc1_w')\n",
    "    with tf.name_scope('fc1_b'):\n",
    "        fc1_b = bias_variable([512],name='fc1_b')\n",
    "    #把池化层2的输出扁平化为1维\n",
    "    with tf.name_scope('conv2_pool_flat'):\n",
    "        conv5_pool_flat = tf.reshape(conv5_pool,[-1,12*15*20],name='conv2_pool_flat')\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        wx_plus_b = tf.matmul(conv5_pool_flat,fc1_w) + fc1_b\n",
    "    with tf.name_scope('relu'):\n",
    "        h_fc1 = tf.nn.relu(wx_plus_b)\n",
    "    with tf.name_scope('keep_prob'):\n",
    "        keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "    with tf.name_scope('fc1_drop'):\n",
    "        fc1_drop = tf.nn.dropout(h_fc1,keep_prob,name='fc1_drop')\n",
    "        \n",
    "#第二个全连接层    \n",
    "with tf.name_scope('fc2'):\n",
    "    with tf.name_scope('fc2_w'):\n",
    "        fc2_w = weight_variable([512,1],name='fc2_w')\n",
    "    with tf.name_scope('fc2_b'):\n",
    "        fc2_b = bias_variable([1],name='fc2_b')\n",
    "    with tf.name_scope('wx_plus_b2'):\n",
    "        wx_plus_b2 = tf.matmul(fc1_drop,fc2_w) + fc2_b\n",
    "    with tf.name_scope('prediction'):\n",
    "        prediction = wx_plus_b2\n",
    "        \n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.square(prediction - y),name='loss')\n",
    "    tf.summary.scalar('loss',loss)\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    train = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    \n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_img,batch_labels = next_batch(sur_img,sur_labels,batch_size)\n",
    "    saver.restore(sess,'F:/code/eyediagram/my_eye/leishen/net/my_net.ckpt')\n",
    "    print(sess.run(loss,feed_dict={x: batch_img,y: batch_labels,keep_prob:1.0}))\n",
    "    sur_prediction = sess.run(prediction,feed_dict = {x:batch_img,y:batch_labels,keep_prob:1.0})\n",
    "    print(sur_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(-np.log2(sur_labels)+1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sur_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(2**(-sur_prediction)-1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sur_labels-(2**(-sur_prediction)-1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
